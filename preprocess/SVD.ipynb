{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVD.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"6MRPJxqsOO5R"},"source":["import pandas as pd\n","import numpy as np\n","import scipy\n","from scipy.linalg import sqrtm\n","from datetime import datetime\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZANE1NJqOifI","executionInfo":{"status":"ok","timestamp":1621392228529,"user_tz":420,"elapsed":1625,"user":{"displayName":"Mayura Patwardhan","photoUrl":"","userId":"05534102659532327375"}},"outputId":"c9eb4569-6326-4a74-9a2b-d5b44e94f676"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\",force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t0NUdLxzOj74"},"source":["dateparse = lambda x: datetime.utcfromtimestamp(int(x)).strftime('%Y-%m-%d %H:%M:%S')\n","\n","files_path = '/content/drive/MyDrive/CSE547_Final_Project/ml-25m'\n","ratings_file = os.path.join(files_path, \"ratings.csv\")\n","movies_file = os.path.join(files_path, \"movies.csv\")\n","user_movie_ratings_matrix = os.path.join(files_path, \"user_movie_ratings_matrix.csv\")\n","\n","data = pd.read_csv(   ratings_file, \n","                            parse_dates=['timestamp'], \n","                            date_parser=dateparse)\n","movies_df = pd.read_csv(movies_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjVoFEHaOu2P","executionInfo":{"status":"ok","timestamp":1621392270429,"user_tz":420,"elapsed":43523,"user":{"displayName":"Mayura Patwardhan","photoUrl":"","userId":"05534102659532327375"}},"outputId":"280bfefb-df2e-458c-cbc7-3c65ed4b7a11"},"source":["data['userId'] = data['userId'].astype('str')\n","data['movieId'] = data['movieId'].astype('str')\n","\n","users = data['userId'].unique() #list of all users\n","movies = data['movieId'].unique() #list of all movies\n","\n","print(\"Number of users\", len(users))\n","print(\"Number of movies\", len(movies))\n","\n","print(data.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of users 162541\n","Number of movies 59047\n","  userId movieId  rating           timestamp\n","0      1     296     5.0 2006-05-17 15:34:04\n","1      1     306     3.5 2006-05-17 12:26:57\n","2      1     307     5.0 2006-05-17 12:27:08\n","3      1     665     5.0 2006-05-17 15:13:40\n","4      1     899     3.5 2006-05-17 12:21:50\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OMgelmQbPLGR"},"source":["test = pd.DataFrame(columns=data.columns)\n","train = pd.DataFrame(columns=data.columns)\n","\n","test_ratio = 0.2 #fraction of data to be used as test set.\n","\n","for u in users:\n","    temp = data[data['userId'] == u]\n","    n = len(temp)\n","    test_size = int(test_ratio*n)\n","\n","    temp = temp.sort_values('timestamp').reset_index()\n","    temp.drop('index', axis=1, inplace=True)\n","        \n","    dummy_test = temp.iloc[n-1-test_size :]\n","    dummy_train = temp.iloc[: n-2-test_size]\n","        \n","    test = pd.concat([test, dummy_test])\n","    train = pd.concat([train, dummy_train])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yQNlBr8QP18y"},"source":["def create_utility_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\n","    \"\"\"\n","        :param data:      Array-like, 2D, nx3\n","        :param formatizer:pass the formatizer\n","        :return:          utility matrix (n x m), n=users, m=items\n","    \"\"\"\n","        \n","    itemField = formatizer['item']\n","    userField = formatizer['user']\n","    valueField = formatizer['value']\n","\n","    userList = data.iloc[:,userField].tolist()\n","    itemList = data.iloc[:,itemField].tolist()\n","    valueList = data.iloc[:,valueField].tolist()\n","    \n","    users = list(set(data.iloc[:,userField]))\n","    items = list(set(data.iloc[:,itemField]))\n","    \n","    users_index = {users[i]: i for i in range(len(users))}\n","    \n","    pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n","    \n","    for i in range(0,len(data)):\n","        item = itemList[i]\n","        user = userList[i]\n","        value = valueList[i]\n","        \n","        pd_dict[item][users_index[user]] = value\n","    \n","    X = pd.DataFrame(pd_dict)\n","    \n","    X.index = users\n","        \n","    itemcols = list(X.columns)\n","    items_index = {itemcols[i]: i for i in range(len(itemcols))}\n","    # users_index gives us a mapping of user_id to index of user\n","    # items_index provides the same for items\n","    return X, users_index, items_index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WwaPLQ8P14i"},"source":["def svd(train, k):\n","    utilMat = np.array(train)\n","    \n","    # the nan or unavailable entries are masked\n","    mask = np.isnan(utilMat)\n","    masked_arr = np.ma.masked_array(utilMat, mask)\n","    item_means = np.mean(masked_arr, axis=0)\n","    \n","    # nan entries will replaced by the average rating for each item\n","    utilMat = masked_arr.filled(item_means)\n","    x = np.tile(item_means, (utilMat.shape[0],1))\n","    \n","    # we remove the per item average from all entries.\n","    # the above mentioned nan entries will be essentially zero now\n","    utilMat = utilMat - x\n","    \n","    # The magic happens here. U and V are user and item features\n","    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\n","    s=np.diag(s)\n","    \n","    # we take only the k most significant features\n","    s=s[0:k,0:k]\n","    U=U[:,0:k]\n","    V=V[0:k,:]\n","    \n","    s_root=sqrtm(s)\n","    \n","    Usk=np.dot(U,s_root)\n","    skV=np.dot(s_root,V)\n","    \n","    UsV = np.dot(Usk, skV)\n","    \n","    UsV = UsV + x\n","    print(\"svd done\")\n","    \n","    return UsV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoPj9p6_QQxR"},"source":["def rmse(true, pred):\n","    # this will be used towards the end\n","    x = true - pred\n","    return sum([xi*xi for xi in x])/len(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WalSQDsiQPf2","executionInfo":{"status":"ok","timestamp":1621388271939,"user_tz":420,"elapsed":6152,"user":{"displayName":"Apoorv Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjO0ftIG0bDuKlCjMrdHvLDCwUreEcBf3lAT5gp=s64","userId":"09578640252499880764"}},"outputId":"cbfa8aeb-2e7f-42c2-f9d4-03c0bd42c967"},"source":["# to test the performance over a different number of features\n","no_of_features = [100, 200, 500, 1000, 5000, 10000]\n","utilMat, users_index, items_index = create_utility_matrix(train)\n","\n","for f in no_of_features[:1]: \n","    svdout = svd(utilMat, k=f)\n","    print(svdout.shape)\n","    pred = [] #to store the predicted ratings\n","    \n","    for _, row in test.iterrows():\n","        user = row['userId']\n","        item = row['movieId']\n","        u_index = users_index[user]\n","        \n","        if item in items_index:\n","            i_index = items_index[item]\n","            pred_rating = svdout[u_index, i_index]\n","        else:\n","            pred_rating = np.mean(svdout[u_index, :])\n","        \n","        pred.append(pred_rating)\n","\n","    print(rmse(test['rating'], pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["svd done\n","(610, 8204)\n","1.0205173744578095\n"],"name":"stdout"}]}]}